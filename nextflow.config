/*
 * -------------------------------------------------
 *  nfcovid config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Global default params, used in configs
params {

  // Options: Generic
  input = 'samplesheet.csv'

  single_end = false

  // Options: Read Trimming
  //cut_mean_quality = 30
  //qualified_quality_phred = 30
  //unqualified_percent_limit = 10
  //min_trim_length = 50
  //skip_adapter_trimming = false
  //skip_amplicon_trimming = false
  save_trimmed = false
  fastp = false

  // Options: Read alignment 
  save_align_intermeds = false
  filter_unmapped = false
  min_mapped_reads = 1000
  
  // Options: QC
  skip_fastqc = false

  // Boilerplate options
  outdir = 'results'
  publish_dir_mode = 'copy'
  name = false
  help = false
  tracedir = "${params.outdir}/pipeline_info"
  //custom_config_version = 'master'
  //custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
}

// Container slug. Stable releases should specify release tag!
// Developmental code should specify :dev
process.container = 'francesccatala/nfcovid-1.0'

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

profiles {
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

